import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

from link_tables import apply_links

df = pd.read_excel(os.path.join("filtered_datasets", "bbOrders_filtered.xlsx"))
df = apply_links(df)

columns = [
    '–¢–∏–ø–¢–°', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ–ü–∞—Å—Å–∞–∂–∏—Ä–æ–≤', '–ó–∞–∫–∞–∑—á–∏–∫', '–ö–æ–Ω—Ç–∞–∫—Ç–Ω–æ–µ–õ–∏—Ü–æ',
    '–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è', '–û—Ç–≤–µ—Ç—Å–≤–µ–Ω–Ω—ã–π', '–¢–°', '–í–æ–¥–∏—Ç–µ–ª—å',
    '–ó–∞–≥—Ä—É–∑–∫–∞–ü—É–Ω–∫—Ç', '–†–∞–∑–≥—Ä—É–∑–∫–∞–ü—É–Ω–∫—Ç',
    '–¢–∏–ø–ó–∞–∫–∞–∑–∞', '–¢–∞—Ä–∏—Ñ', '–§–∞–∫—Ç–∏—á–µ—Å–∫–∞—è–°—Ç–æ–∏–º–æ—Å—Ç—å', '–¶–µ–Ω–∞–ó–∞–ß–∞—Å',
    '–ú–Ω–æ–≥–æ–¥–Ω–µ–≤–Ω—ã–π', '–ó–∞—Ä—É–±–µ–∂–Ω–∞—è–ü–æ–µ–∑–¥–∫–∞', '–¢—Ä–µ–±—É–µ—Ç—Å—è–¢—É–∞–ª–µ—Ç', '–ë–∞–≥–∞–∂'
]

df = df[columns].dropna(subset=['–¢–∏–ø–¢–°', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ–ü–∞—Å—Å–∞–∂–∏—Ä–æ–≤'])

# –î–æ–±–∞–≤–∏–º –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ "–ú–∞—Ä—à—Ä—É—Ç"
df['–ú–∞—Ä—à—Ä—É—Ç'] = df['–ó–∞–≥—Ä—É–∑–∫–∞–ü—É–Ω–∫—Ç'].astype(str) + " ‚Üí " + df['–†–∞–∑–≥—Ä—É–∑–∫–∞–ü—É–Ω–∫—Ç'].astype(str)
df = df.drop(['–ó–∞–≥—Ä—É–∑–∫–∞–ü—É–Ω–∫—Ç', '–†–∞–∑–≥—Ä—É–∑–∫–∞–ü—É–Ω–∫—Ç'], axis=1)

target = '–¢–∏–ø–¢–°'
features = [col for col in df.columns if col != target]

df_encoded = df.copy()
encoders = {}

for col in df_encoded.columns:
    if df_encoded[col].dtype == 'object':
        le = LabelEncoder()
        df_encoded[col] = le.fit_transform(df_encoded[col].astype(str))
        encoders[col] = le

X = df_encoded[features]
y = df_encoded[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

importances = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)
top_10 = importances.head(10).index.tolist()

X_train_top = X_train[top_10]
X_test_top = X_test[top_10]

rf.fit(X_train_top, y_train)
y_pred_rf = rf.predict(X_test_top)

print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

joblib.dump(rf, 'models/model_typeTS.pkl')
joblib.dump(encoders, 'models/encoders.pkl')

plt.figure(figsize=(10, 6))
sns.barplot(x=importances.head(10).values, y=importances.head(10).index)
plt.title("–¢–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¢–∏–ø–¢–° (RandomForest)")
plt.xlabel("–í–∞–∂–Ω–æ—Å—Ç—å")
plt.tight_layout()
plt.grid(True)
plt.show()


# –ê–Ω–∞–ª–∏–∑ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π
import seaborn as sns
import matplotlib.pyplot as plt

print("\n--- üìé –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤—è–∑–µ–π ---")

# –°–≤—è–∑—å –º–µ–∂–¥—É –ó–∞–∫–∞–∑—á–∏–∫–æ–º –∏ –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–µ–π
cross1 = pd.crosstab(df['–ó–∞–∫–∞–∑—á–∏–∫'], df['–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è'])
print("\n–ó–∞–∫–∞–∑—á–∏–∫ √ó –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–æ–∫:", len(cross1.stack()))
print("–ß–∏—Å–ª–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –Ω–∞ –æ–¥–Ω–æ–≥–æ –∑–∞–∫–∞–∑—á–∏–∫–∞ (—Å—Ä–µ–¥–Ω–µ–µ):", cross1.astype(bool).sum(axis=1).mean())

# –°–≤—è–∑—å –º–µ–∂–¥—É –ó–∞–∫–∞–∑—á–∏–∫–æ–º –∏ –ö–æ–Ω—Ç–∞–∫—Ç–Ω—ã–º –ª–∏—Ü–æ–º
cross2 = pd.crosstab(df['–ó–∞–∫–∞–∑—á–∏–∫'], df['–ö–æ–Ω—Ç–∞–∫—Ç–Ω–æ–µ–õ–∏—Ü–æ'])
print("\n–ó–∞–∫–∞–∑—á–∏–∫ √ó –ö–æ–Ω—Ç–∞–∫—Ç–Ω–æ–µ–õ–∏—Ü–æ ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–æ–∫:", len(cross2.stack()))
print("–ß–∏—Å–ª–æ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö –ª–∏—Ü –Ω–∞ –æ–¥–Ω–æ–≥–æ –∑–∞–∫–∞–∑—á–∏–∫–∞ (—Å—Ä–µ–¥–Ω–µ–µ):", cross2.astype(bool).sum(axis=1).mean())

# –°–≤—è–∑—å –º–µ–∂–¥—É –ó–∞–∫–∞–∑—á–∏–∫–æ–º –∏ –û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–º
cross3 = pd.crosstab(df['–ó–∞–∫–∞–∑—á–∏–∫'], df['–û—Ç–≤–µ—Ç—Å–≤–µ–Ω–Ω—ã–π'])
print("\n–ó–∞–∫–∞–∑—á–∏–∫ √ó –û—Ç–≤–µ—Ç—Å–≤–µ–Ω–Ω—ã–π ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–≤—è–∑–æ–∫:", len(cross3.stack()))
print("–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã—Ö –Ω–∞ –æ–¥–Ω–æ–≥–æ –∑–∞–∫–∞–∑—á–∏–∫–∞ (—Å—Ä–µ–¥–Ω–µ–µ):", cross3.astype(bool).sum(axis=1).mean())

# –í–æ–¥–∏—Ç–µ–ª—å ‚Üî –¢–°
print("\n–í–æ–¥–∏—Ç–µ–ª—å √ó –¢–° (–Ω–∞ —Å–∫–æ–ª—å–∫–æ –¢–° —Ä–∞–±–æ—Ç–∞–µ—Ç 1 –≤–æ–¥–∏—Ç–µ–ª—å):")
vod_tts = df.groupby('–í–æ–¥–∏—Ç–µ–ª—å')['–¢–°'].nunique().sort_values(ascending=False)
print(vod_tts.describe())
plt.figure(figsize=(8, 4))
sns.histplot(vod_tts, bins=20)
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¢–° –Ω–∞ –æ–¥–Ω–æ–≥–æ –≤–æ–¥–∏—Ç–µ–ª—è")
plt.xlabel("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¢–°")
plt.tight_layout()
plt.show()

# –¢–∏–ø–¢–° ‚Üî –¢–° (—Å–≤—è–∑—å —Ç–∏–ø–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –¢–°)
print("\n–¢–° √ó –¢–∏–ø–¢–° ‚Äî —Å–∫–æ–ª—å–∫–æ –¢–° —Ä–∞–±–æ—Ç–∞—é—Ç –ø–æ–¥ —Ä–∞–∑–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞:")
tts_typets = df.groupby('–¢–°')['–¢–∏–ø–¢–°'].nunique().sort_values(ascending=False)
print(tts_typets.describe())
plt.figure(figsize=(8, 4))
sns.histplot(tts_typets, bins=10)
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¢–∏–ø–¢–° –Ω–∞ –æ–¥–Ω—É –¢–°")
plt.xlabel("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¢–∏–ø–¢–°")
plt.tight_layout()
plt.show()

